{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca341c9",
   "metadata": {},
   "source": [
    "# 7. Applications of Data Mining for Fraud Detection - Part 1: Banking and Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5da655",
   "metadata": {},
   "source": [
    "In this video, we will walk through a comprehensive process of applying machine learning techniques using real-life data. We will train test and evaluate from the following family of algorithms:\n",
    "\n",
    "1. Supervised\n",
    "2. Ensemble\n",
    "3. Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1d36d",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbfe1cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed453f0f",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc66819f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "0     1   9839.64       170136.0       160296.36             0.0   \n",
       "1     1   1864.28        21249.0        19384.72             0.0   \n",
       "2     1    181.00          181.0            0.00             0.0   \n",
       "3     1    181.00          181.0            0.00         21182.0   \n",
       "4     1  11668.14        41554.0        29885.86             0.0   \n",
       "\n",
       "   newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0             0.0        0               0  \n",
       "1             0.0        0               0  \n",
       "2             0.0        1               0  \n",
       "3             0.0        1               0  \n",
       "4             0.0        0               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('PS_20174392719_1491204439457_log.csv')\n",
    "df = df.head(60000)\n",
    "# Drop the 'type' and 'nameOrig' and 'nameDest' columns as they are not required for our prediction\n",
    "df = df.drop(['type', 'nameOrig', 'nameDest'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeab7924",
   "metadata": {},
   "source": [
    "# Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5143d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('isFraud', axis=1)\n",
    "y = df['isFraud']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b4322",
   "metadata": {},
   "source": [
    "# Supervised Learning Modelling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8fcb77",
   "metadata": {},
   "source": [
    "## Define hyperparameters to tune for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aab7f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n",
    "dt_params = {'criterion': ['gini', 'entropy'], 'max_depth': [5, 10, 20]}\n",
    "nb_params = {}\n",
    "svm_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "nn_params = {'hidden_layer_sizes': [(50,), (100,), (50, 50)], 'activation': ['relu', 'logistic'], 'solver': ['adam', 'sgd'], 'alpha': [0.0001, 0.001, 0.01]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f183e08e",
   "metadata": {},
   "source": [
    "## Train and Test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96ac71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr_gs = GridSearchCV(lr, lr_params, scoring='roc_auc', cv=5)\n",
    "lr_gs.fit(X_train, y_train)\n",
    "lr_preds = lr_gs.predict(X_test)\n",
    "\n",
    "# Decision trees\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_gs = GridSearchCV(dt, dt_params, scoring='roc_auc', cv=5)\n",
    "dt_gs.fit(X_train, y_train)\n",
    "dt_preds = dt_gs.predict(X_test)\n",
    "\n",
    "# Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb_gs = GridSearchCV(nb, nb_params, scoring='roc_auc', cv=5)\n",
    "nb_gs.fit(X_train, y_train)\n",
    "nb_preds = nb_gs.predict(X_test)\n",
    "\n",
    "# SVM\n",
    "svm = SVC(probability=True,max_iter=1000)\n",
    "svm_gs = GridSearchCV(svm, svm_params, scoring='roc_auc', cv=5)\n",
    "svm_gs.fit(X_train, y_train)\n",
    "svm_preds = svm_gs.predict(X_test)\n",
    "\n",
    "# Neural Networks\n",
    "nn = MLPClassifier(max_iter=1000)\n",
    "nn_gs = GridSearchCV(nn, nn_params, scoring='roc_auc', cv=5)\n",
    "nn_gs.fit(X_train, y_train)\n",
    "nn_preds = nn_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998329b8",
   "metadata": {},
   "source": [
    "## Evaluation of algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ec211b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.9982222222222222\n",
      "Precision: 0.5833333333333334\n",
      "Recall: 0.20588235294117646\n",
      "F1 Score: 0.3043478260869565\n",
      "AUC Score: 0.6028020247395406\n",
      "\n",
      "\n",
      "Decision Trees Metrics:\n",
      "Accuracy: 0.998\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "AUC Score: 0.499944339307581\n",
      "\n",
      "\n",
      "Naive Bayes Metrics:\n",
      "Accuracy: 0.9813333333333333\n",
      "Precision: 0.003289473684210526\n",
      "Recall: 0.029411764705882353\n",
      "F1 Score: 0.0059171597633136085\n",
      "AUC Score: 0.5062732874514605\n",
      "\n",
      "\n",
      "SVM Metrics:\n",
      "Accuracy: 0.9981666666666666\n",
      "Precision: 1.0\n",
      "Recall: 0.029411764705882353\n",
      "F1 Score: 0.05714285714285715\n",
      "AUC Score: 0.5147058823529411\n",
      "\n",
      "\n",
      "Neural Networks Metrics:\n",
      "Accuracy: 0.9981111111111111\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "AUC Score: 0.5\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AMarkou\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, lr_preds))\n",
    "print(\"Precision:\", precision_score(y_test, lr_preds))\n",
    "print(\"Recall:\", recall_score(y_test, lr_preds))\n",
    "print(\"F1 Score:\", f1_score(y_test, lr_preds))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, lr_preds))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Decision Trees Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, dt_preds))\n",
    "print(\"Precision:\", precision_score(y_test, dt_preds))\n",
    "print(\"Recall:\", recall_score(y_test, dt_preds))\n",
    "print(\"F1 Score:\", f1_score(y_test, dt_preds))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, dt_preds))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Naive Bayes Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, nb_preds))\n",
    "print(\"Precision:\", precision_score(y_test, nb_preds))\n",
    "print(\"Recall:\", recall_score(y_test, nb_preds))\n",
    "print(\"F1 Score:\", f1_score(y_test, nb_preds))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, nb_preds))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"SVM Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_preds))\n",
    "print(\"Precision:\", precision_score(y_test, svm_preds))\n",
    "print(\"Recall:\", recall_score(y_test, svm_preds))\n",
    "print(\"F1 Score:\", f1_score(y_test, svm_preds))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, svm_preds))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Neural Networks Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, nn_preds))\n",
    "print(\"Precision:\", precision_score(y_test, nn_preds))\n",
    "print(\"Recall:\", recall_score(y_test, nn_preds))\n",
    "print(\"F1 Score:\", f1_score(y_test, nn_preds))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, nn_preds))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371bb60",
   "metadata": {},
   "source": [
    "# Ensemble Learning Modelling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed3f3e",
   "metadata": {},
   "source": [
    "## Define hyperparameters to tune for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55c92f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_params = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_samples': [0.5, 1.0],\n",
    "    'max_features': [0.5, 1.0],\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "ada_params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "    'subsample': [0.5, 1.0],\n",
    "    'max_depth': [3, 5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 1.0],\n",
    "    'subsample': [0.5, 1.0],\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'colsample_bytree': [0.5, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebda8f8",
   "metadata": {},
   "source": [
    "## Train and Test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03ed68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "bag = BaggingClassifier()\n",
    "bag_gs = GridSearchCV(bag, bag_params, scoring='roc_auc', cv=5)\n",
    "bag_gs.fit(X_train, y_train)\n",
    "bag_preds = bag_gs.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf_gs = GridSearchCV(rf, rf_params, scoring='roc_auc', cv=5)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "rf_preds = rf_gs.predict(X_test)\n",
    "\n",
    "# AdaBoost\n",
    "ada = AdaBoostClassifier()\n",
    "ada_gs = GridSearchCV(ada, ada_params, scoring='roc_auc', cv=5)\n",
    "ada_gs.fit(X_train, y_train)\n",
    "ada_preds = ada_gs.predict(X_test)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier()\n",
    "gb_gs = GridSearchCV(gb, gb_params, scoring='roc_auc', cv=5)\n",
    "gb_gs.fit(X_train, y_train)\n",
    "gb_preds = gb_gs.predict(X_test) \n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier()\n",
    "xgb_gs = GridSearchCV(xgb, xgb_params, scoring='roc_auc', cv=5)\n",
    "xgb_gs.fit(X_train, y_train)\n",
    "xgb_preds = xgb_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd708957",
   "metadata": {},
   "source": [
    "## Evaluation of algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f680e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Metrics:\n",
      "Accuracy: 0.9981666666666666\n",
      "Precision: 1.0\n",
      "Recall: 0.029411764705882353\n",
      "F1 Score: 0.05714285714285715\n",
      "AUC Score: 0.5147058823529411\n",
      "\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.9982222222222222\n",
      "Precision: 1.0\n",
      "Recall: 0.058823529411764705\n",
      "F1 Score: 0.1111111111111111\n",
      "AUC Score: 0.5294117647058824\n",
      "\n",
      "\n",
      "AdaBoost Metrics:\n",
      "Accuracy: 0.9981666666666666\n",
      "Precision: 1.0\n",
      "Recall: 0.029411764705882353\n",
      "F1 Score: 0.05714285714285715\n",
      "AUC Score: 0.5147058823529411\n",
      "\n",
      "\n",
      "Gradient Boosting Metrics:\n",
      "Accuracy: 0.9984444444444445\n",
      "Precision: 0.875\n",
      "Recall: 0.20588235294117646\n",
      "F1 Score: 0.33333333333333337\n",
      "AUC Score: 0.6029133461243786\n",
      "\n",
      "\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.9992777777777778\n",
      "Precision: 0.9565217391304348\n",
      "Recall: 0.6470588235294118\n",
      "F1 Score: 0.7719298245614036\n",
      "AUC Score: 0.8235015814184964\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Bagging Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, bag_preds))\n",
    "print(\"Precision:\", precision_score(y_test, bag_preds))\n",
    "print(\"Recall:\", recall_score(y_test, bag_preds))\n",
    "print(\"F1 Score:\", f1_score(y_test, bag_preds))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, bag_preds)) \n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, rf_preds))\n",
    "print(\"Precision:\", precision_score(y_test, rf_preds))\n",
    "print(\"Recall:\", recall_score(y_test, rf_preds))\n",
    "print(\"F1 Score:\", f1_score(y_test, rf_preds))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, rf_preds))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"AdaBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, ada_preds))\n",
    "print(\"Precision:\", precision_score(y_test, ada_preds))\n",
    "print(\"Recall:\", recall_score(y_test, ada_preds))\n",
    "print(\"F1 Score:\", f1_score(y_test, ada_preds))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, ada_preds))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Gradient Boosting Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, gb_preds))\n",
    "print(\"Precision:\", precision_score(y_test, gb_preds))\n",
    "print(\"Recall:\", recall_score(y_test, gb_preds))\n",
    "print(\"F1 Score:\", f1_score(y_test, gb_preds))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, gb_preds))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"XGBoost Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, xgb_preds))\n",
    "print(\"Precision:\", precision_score(y_test, xgb_preds))\n",
    "print(\"Recall:\", recall_score(y_test, xgb_preds))\n",
    "print(\"F1 Score:\", f1_score(y_test, xgb_preds))\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, xgb_preds))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a376bf14",
   "metadata": {},
   "source": [
    "# Do the same process for Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc542839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Base models\n",
    "#lr = LogisticRegression()\n",
    "#dt = DecisionTreeClassifier()\n",
    "#svm = SVC(probability=True)\n",
    "\n",
    "# Hyperparameters for the base models\n",
    "#lr_params = {'logistic_regression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "#dt_params = {'decision_tree__max_depth': [None, 5, 10, 15, 20]}\n",
    "#svm_params = {'support_vector_machine__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "#              'support_vector_machine__gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "#              'support_vector_machine__kernel': ['linear', 'rbf']}\n",
    "\n",
    "#base_models = [\n",
    "#    ('logistic_regression', GridSearchCV(lr, lr_params, cv=5)),\n",
    "#    ('decision_tree', GridSearchCV(dt, dt_params, cv=5)),\n",
    "#    ('support_vector_machine', GridSearchCV(svm, svm_params, cv=5))\n",
    "#]\n",
    "\n",
    "# Meta model\n",
    "#rf = RandomForestClassifier()\n",
    "\n",
    "# Hyperparameters for the meta model\n",
    "#rf_params = {'randomforestclassifier__n_estimators': [50, 100, 150, 200],\n",
    "#             'randomforestclassifier__max_depth': [None, 5, 10, 15, 20]}\n",
    "\n",
    "# Define the stacking classifier\n",
    "#stacking_model = StackingClassifier(estimators=base_models, final_estimator=GridSearchCV(rf, rf_params, cv=5))\n",
    "\n",
    "# Fit the model to our training data\n",
    "#stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "#stack_preds = stacking_model.predict(X_test)\n",
    "\n",
    "#print(\"Stacking Model Metrics:\")\n",
    "#print(\"Accuracy:\", accuracy_score(y_test, stack_preds))\n",
    "#print(\"Precision:\", precision_score(y_test, stack_preds))\n",
    "#print(\"Recall:\", recall_score(y_test, stack_preds))\n",
    "#print(\"F1 Score:\", f1_score(y_test, stack_preds))\n",
    "#print(\"AUC Score:\", roc_auc_score(y_test, stack_preds))\n",
    "#print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687a7482",
   "metadata": {},
   "source": [
    "# Unsupervised Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb31407a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Rate for each cluster:\n",
      "\n",
      "cluster\n",
      "0    0.002113\n",
      "1    0.000000\n",
      "Name: isFraud, dtype: float64\n",
      "Silhouette Score:  0.654287223507193\n"
     ]
    }
   ],
   "source": [
    "# Apply K-Means clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "# Predict the clusters for test data\n",
    "clusters = kmeans.predict(X_test)\n",
    "\n",
    "# Append clusters and actual fraud labels to the test dataset\n",
    "test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "test_df['cluster'] = clusters\n",
    "test_df['isFraud'] = y_test.values\n",
    "\n",
    "# Calculate fraud rates for each cluster\n",
    "cluster_fraud_rates = test_df.groupby('cluster')['isFraud'].mean()\n",
    "\n",
    "print(\"Fraud Rate for each cluster:\\n\")\n",
    "print(cluster_fraud_rates)\n",
    "\n",
    "print(\"Silhouette Score: \", silhouette_score(X_test, clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d9d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
